accuracy_table_bestpred <- financebirds_ts_bestpred %>%
count(type, ptype) %>%
group_by(type) %>%
mutate(Accuracy = n[type==ptype]/sum(n)) %>%
pivot_wider(names_from = "ptype",
values_from = n) %>%
select(type, birdsongs, finance, Accuracy)
# Calculate overall accuracy
accuracy_bestpred <- accuracy(financebirds_ts_bestpred, type, ptype)
kable(accuracy_table_bestpred, format = "html",
caption = "Confusion Matrix (Best Tree Model After Tuning)") %>%
kable_styling()
kable(accuracy_bestpred, format = "html",
caption = "Overall Accuracy (Best Tree Model After Tuning)") %>%
kable_styling()
set.seed(121)
bt_spec <- boost_tree() %>%
set_mode("classification") %>%
set_engine("xgboost")
fb_fit_bt <- bt_spec %>%
fit(type~., data = financebirds_tr)
fb_ts_bt_pred <- financebirds_ts %>%
mutate(ptype = predict(fb_fit_bt,
financebirds_ts)$.pred_class)
fb_ts_bt_pred_acc <- accuracy(fb_ts_bt_pred, type, ptype)
kable(fb_ts_bt_pred_acc, format = "html",
caption = "Overall Accuracy (Boosted Tree Model)") %>%
kable_styling()
fb_ts_bt_pred_table <- fb_ts_bt_pred %>%
count(type, ptype) %>%
group_by(type) %>%
mutate(Accuracy = n[type==ptype]/sum(n)) %>%
pivot_wider(names_from = "ptype",
values_from = n, values_fill = 0) %>%
select(type, birdsongs, finance, Accuracy)
kable(fb_ts_bt_pred_table, format = "html",
caption = "Confusion Matrix (Boosted Tree Model)") %>%
kable_styling()
#| label: fig-4
#| fig-cap: Boosted Tree Model Trained on Finance and Birdsongs Data
xgb.plot.tree(model = fb_fit_bt$fit, trees = 0, render = TRUE,
width = 10, height = 10)
set.seed(121)
rf_spec <- rand_forest(mtry=2, trees=1000) %>%
set_mode("classification") %>%
set_engine("randomForest")
fb_fit_rf <- rf_spec %>%
fit(type ~ ., data = financebirds_tr)
fb_fit_rf
fb_ts_rf_pred <- financebirds_ts %>%
mutate(ptype = predict(fb_fit_rf, financebirds_ts)$.pred_class)
fb_ts_rf_pred_acc <- accuracy(fb_ts_rf_pred, type, ptype)
kable(fb_ts_rf_pred_acc, format = "html",
caption = "Overall Accuracy (Random Forest Model)") %>%
kable_styling()
fb_ts_rf_pred_table <- fb_ts_rf_pred %>%
count(type, ptype) %>%
group_by(type) %>%
mutate(Accuracy = n[type==ptype]/sum(n)) %>%
pivot_wider(names_from = "ptype",
values_from = n, values_fill = 0) %>%
select(type, birdsongs, finance, Accuracy)
kable(fb_ts_rf_pred_table, format = "html",
caption = "Confusion Matrix (Random Forest Model)") %>%
kable_styling()
#| label: fig-5
#| fig-cap: Variable Importance Plot showing 'MeanDecreaseGini' on the X-axis. Higher values on the X-axis indicate greater importance of the corresponding variables in predicting the target outcome.
varImpPlot(fb_fit_rf$fit,
main = "Variable Importance Plot (Random Forest Model)",
col = "darkblue", pch = 19, lwd = 2, lty = 2)
# LDA Model
financebirds_tr$type <- factor(financebirds_tr$type)
lda_spec <- discrim_linear() %>%
set_mode("classification") %>%
set_engine("MASS", prior = c(0.5, 0.5))
lda_fit <- lda_spec %>%
fit(type ~ ., data = financebirds_tr)
# Logistic Model
log_reg <- logistic_reg() %>%
set_engine("glm") %>%
set_mode("classification")
log_fit <- log_reg %>%
fit(type ~ ., data = financebirds_tr)
# ROC curve for LDA model
lda_predicted_probs <- predict(lda_fit, financebirds_ts, type = "prob")
lda_prob_birdsongs <- lda_predicted_probs$.pred_birdsongs
lda_roc <- roc(financebirds_ts$type == "birdsongs", lda_prob_birdsongs)
# Calculate AUC for LDA model
lda_auc <- round(auc(lda_roc), 3)
# ROC curve for Logistic model
log_predicted_probs <- predict(log_fit, financebirds_ts, type = "prob")
log_prob_birdsongs <- log_predicted_probs$.pred_birdsongs
log_roc <- roc(financebirds_ts$type == "birdsongs", log_prob_birdsongs)
# Calculate AUC for Logistic model
log_auc <- round(auc(log_roc), 3)
# ROC curve for best tree model
besttree_predicted_probs <- predict(final_fit, financebirds_ts, type = "prob")
besttree_prob_birdsongs <- besttree_predicted_probs$.pred_birdsongs
besttree_roc <- roc(financebirds_ts$type == "birdsongs", besttree_prob_birdsongs)
# Calculate AUC for logistic model
besttree_auc <- round(auc(besttree_roc), 3)
# ROC curve for boosted tree model
bt_predicted_probs <- predict(fb_fit_bt, financebirds_ts, type = "prob")
bt_prob_birdsongs <- bt_predicted_probs$.pred_birdsongs
bt_roc <- roc(financebirds_ts$type == "birdsongs", bt_prob_birdsongs)
# Calculate AUC for logistic model
bt_auc <- round(auc(bt_roc), 3)
# ROC curve for random forest tree model
rf_predicted_probs <- predict(fb_fit_rf, financebirds_ts, type = "prob")
rf_prob_birdsongs <- rf_predicted_probs$.pred_birdsongs
rf_roc <- roc(financebirds_ts$type == "birdsongs", rf_prob_birdsongs)
# Calculate AUC for logistic model
rf_auc <- round(auc(rf_roc), 3)
#| label: fig-6
#| fig-cap: ROC Curve Comparison of Different Machine Learning Models. The ROC curves depict the performance of various models in classifying `birdsongs` (i.e. the positive class). Each curve represents a different model - Tuned Tree (blue), Boosted Tree (red), Random Forest (dark green), Linear Discriminant Analysis (LDA) (orange), and Logistic Regression (maroon). The area under the ROC curve (AUC) values for each model are provided in the legend.
# Plot ROC curve for the first model (Tuned Tree)
plot(besttree_roc, main = "ROC Curve Comparison",
col = "blue", lwd = 2, lty = 1)
# Add ROC curve for the second model (Boosted Tree)
lines(bt_roc, col = "red", lwd = 2, lty = 1)
# Add ROC curve for the third model (Random Forest)
lines(rf_roc, col = "darkgreen", lwd = 2, lty = 1)
# Add ROC curve for the fourth model (LDA)
lines(lda_roc, col = "orange", lwd = 2, lty = 1)
# Add ROC curve for the fifth model (Logistic)
lines(log_roc, col = "maroon", lwd = 2, lty = 1)
# Add legend for all models
legend("bottomright", legend = c(paste("Best Tree AUC =", besttree_auc),
paste("Boosted Tree AUC =", bt_auc),
paste("Random Forest AUC =", rf_auc),
paste("LDA AUC =", lda_auc),
paste("Log AUC =", log_auc)),
col = c("blue", "red", "darkgreen", "orange", "maroon"), lty = 1, lwd = 2, bty = "n",
inset = c(0, 0))
#| label: fig-6
#| fig-cap: ROC Curve Comparison of Different Machine Learning Models. The ROC curves depict the performance of various models in classifying `birdsongs` (i.e. the positive class). Each curve represents a different model - Tuned Tree (blue), Boosted Tree (red), Random Forest (dark green), Linear Discriminant Analysis (LDA) (orange), and Logistic Regression (maroon). The area under the ROC curve (AUC) values for each model are provided in the legend.
# Plot ROC curve for the first model (Tuned Tree)
plot(besttree_roc, main = "ROC Curve Comparison",
col = "blue", lwd = 2, lty = 1, xlim = c(0, 1), ylim = c(0, 1))
# Add ROC curve for the second model (Boosted Tree)
lines(bt_roc, col = "red", lwd = 2, lty = 1)
# Add ROC curve for the third model (Random Forest)
lines(rf_roc, col = "darkgreen", lwd = 2, lty = 1)
# Add ROC curve for the fourth model (LDA)
lines(lda_roc, col = "orange", lwd = 2, lty = 1)
# Add ROC curve for the fifth model (Logistic)
lines(log_roc, col = "maroon", lwd = 2, lty = 1)
# Add legend for all models
legend("bottomright", legend = c(paste("Best Tree AUC =", besttree_auc),
paste("Boosted Tree AUC =", bt_auc),
paste("Random Forest AUC =", rf_auc),
paste("LDA AUC =", lda_auc),
paste("Log AUC =", log_auc)),
col = c("blue", "red", "darkgreen", "orange", "maroon"), lty = 1, lwd = 2, bty = "n",
inset = c(0, 0))
#| label: fig-6
#| fig-cap: ROC Curve Comparison of Different Machine Learning Models. The ROC curves depict the performance of various models in classifying `birdsongs` (i.e. the positive class). Each curve represents a different model - Tuned Tree (blue), Boosted Tree (red), Random Forest (dark green), Linear Discriminant Analysis (LDA) (orange), and Logistic Regression (maroon). The area under the ROC curve (AUC) values for each model are provided in the legend.
# Plot ROC curve for the first model (Tuned Tree)
plot(besttree_roc, main = "ROC Curve Comparison",
col = "blue", lwd = 2, lty = 1)
# Add ROC curve for the second model (Boosted Tree)
lines(bt_roc, col = "red", lwd = 2, lty = 1)
# Add ROC curve for the third model (Random Forest)
lines(rf_roc, col = "darkgreen", lwd = 2, lty = 1)
# Add ROC curve for the fourth model (LDA)
lines(lda_roc, col = "orange", lwd = 2, lty = 1)
# Add ROC curve for the fifth model (Logistic)
lines(log_roc, col = "maroon", lwd = 2, lty = 1)
# Add legend for all models
legend("bottomright", legend = c(paste("Best Tree AUC =", besttree_auc),
paste("Boosted Tree AUC =", bt_auc),
paste("Random Forest AUC =", rf_auc),
paste("LDA AUC =", lda_auc),
paste("Log AUC =", log_auc)),
col = c("blue", "red", "darkgreen", "orange", "maroon"), lty = 1, lwd = 2, bty = "n",
inset = c(0, 0))
# ROC curve for LDA model
lda_predicted_probs <- predict(lda_fit, financebirds_ts, type = "prob")
lda_prob_birdsongs <- lda_predicted_probs$.pred_birdsongs
lda_roc <- roc_curve(financebirds_ts$type == "birdsongs", lda_prob_birdsongs)
# ROC curve for LDA model
lda_predicted_probs <- predict(lda_fit, financebirds_ts, type = "prob")
lda_prob_birdsongs <- lda_predicted_probs$.pred_birdsongs
lda_roc <- roc(financebirds_ts$type == "birdsongs", lda_prob_birdsongs)
# Calculate AUC for LDA model
lda_auc <- round(auc(lda_roc), 3)
# ROC curve for Logistic model
log_predicted_probs <- predict(log_fit, financebirds_ts, type = "prob")
log_prob_birdsongs <- log_predicted_probs$.pred_birdsongs
log_roc <- roc(financebirds_ts$type == "birdsongs", log_prob_birdsongs)
# Calculate AUC for Logistic model
log_auc <- round(auc(log_roc), 3)
# ROC curve for best tree model
besttree_predicted_probs <- predict(final_fit, financebirds_ts, type = "prob")
besttree_prob_birdsongs <- besttree_predicted_probs$.pred_birdsongs
besttree_roc <- roc(financebirds_ts$type == "birdsongs", besttree_prob_birdsongs)
# Calculate AUC for logistic model
besttree_auc <- round(auc(besttree_roc), 3)
# ROC curve for boosted tree model
bt_predicted_probs <- predict(fb_fit_bt, financebirds_ts, type = "prob")
bt_prob_birdsongs <- bt_predicted_probs$.pred_birdsongs
bt_roc <- roc(financebirds_ts$type == "birdsongs", bt_prob_birdsongs)
# Calculate AUC for logistic model
bt_auc <- round(auc(bt_roc), 3)
# ROC curve for random forest tree model
rf_predicted_probs <- predict(fb_fit_rf, financebirds_ts, type = "prob")
rf_prob_birdsongs <- rf_predicted_probs$.pred_birdsongs
rf_roc <- roc(financebirds_ts$type == "birdsongs", rf_prob_birdsongs)
# Calculate AUC for logistic model
rf_auc <- round(auc(rf_roc), 3)
#| label: fig-6
#| fig-cap: ROC Curve Comparison of Different Machine Learning Models. The ROC curves depict the performance of various models in classifying `birdsongs` (i.e. the positive class). Each curve represents a different model - Tuned Tree (blue), Boosted Tree (red), Random Forest (dark green), Linear Discriminant Analysis (LDA) (orange), and Logistic Regression (maroon). The area under the ROC curve (AUC) values for each model are provided in the legend.
# Plot ROC curve for the first model (Tuned Tree)
plot(besttree_roc, main = "ROC Curve Comparison",
col = "blue", lwd = 2, lty = 1)
# Add ROC curve for the second model (Boosted Tree)
lines(bt_roc, col = "red", lwd = 2, lty = 1)
# Add ROC curve for the third model (Random Forest)
lines(rf_roc, col = "darkgreen", lwd = 2, lty = 1)
# Add ROC curve for the fourth model (LDA)
lines(lda_roc, col = "orange", lwd = 2, lty = 1)
# Add ROC curve for the fifth model (Logistic)
lines(log_roc, col = "maroon", lwd = 2, lty = 1)
# Add legend for all models
legend("bottomright", legend = c(paste("Best Tree AUC =", besttree_auc),
paste("Boosted Tree AUC =", bt_auc),
paste("Random Forest AUC =", rf_auc),
paste("LDA AUC =", lda_auc),
paste("Log AUC =", log_auc)),
col = c("blue", "red", "darkgreen", "orange", "maroon"), lty = 1, lwd = 2, bty = "n",
inset = c(0, 0))
unique(financebirds_ts$type)
library(readr)
library(dplyr)
library(tidyverse)
library(tidymodels)
library(rpart)
library(rpart.plot)
library(kableExtra)
library(randomForest)
library(xgboost)
library(pROC)
library(discrim)
finance_birds <- read_csv("finance_and_birds.csv")
options(digits=2)
financebirds_tidy <- finance_birds %>%
dplyr::select(type, trend, linearity, entropy, x_acf1) %>%
arrange(type) %>%
na.omit()
financebirds_std <- financebirds_tidy %>%
mutate_if(is.numeric, function(x) (x-mean(x))/sd(x))
set.seed(1148)
financebirds_split <- initial_split(financebirds_std, 2/3,
strata = type)
financebirds_tr <- training(financebirds_split)
financebirds_ts <- testing(financebirds_split)
financebirds_tr <- financebirds_tr %>%
mutate(type = as.factor(type))
tree_spec <- decision_tree() %>%
set_mode("classification") %>%
set_engine("rpart")
financebirds_fit_tree <- tree_spec %>%
fit(type~., data = financebirds_tr)
financebirds_fit_tree
#| label: fig-1
#| fig-cap: Default Decision Tree Visualization for Finance and Birdsongs Classification
financebirds_fit_tree %>%
extract_fit_engine() %>%
rpart.plot(type=3, extra=1)
financebirds_ts <- financebirds_ts %>%
mutate(type = as.factor(type))
financebirds_ts_pred <- financebirds_ts %>%
mutate(ptype = predict(financebirds_fit_tree$fit,
financebirds_ts,
type="class"))
# Calculate accuracy for confusion matrix
accuracy_table <- financebirds_ts_pred %>%
count(type, ptype) %>%
group_by(type) %>%
mutate(Accuracy = n[type==ptype]/sum(n)) %>%
pivot_wider(names_from = "ptype",
values_from = n) %>%
select(type, birdsongs, finance, Accuracy)
# Calculate overall accuracy
accuracy_default <- accuracy(financebirds_ts_pred, type, ptype)
kable(accuracy_table, format = "html",
caption = "Confusion Matrix (Default Tree Model)") %>%
kable_styling()
kable(accuracy_default, format = "html",
caption = "Overall Accuracy (Default Tree Model)") %>%
kable_styling()
# Define tuning specifications for decision tree model
tune_spec <-
decision_tree(
tree_depth = tune(),
min_n = tune(),
cost_complexity = tune()
) %>%
set_engine("rpart") %>%
set_mode("classification")
# Define the grid of hyperparameters to search over
tree_grid <- grid_regular(tree_depth(),
min_n(),
cost_complexity(),
levels = 5)
# Define cross-validation folds
set.seed(234)
cell_folds <- vfold_cv(financebirds_tr)
# Define workflow for tuning
set.seed(345)
tree_wf <- workflow() %>%
add_model(tune_spec) %>%
add_formula(type ~ .)
# Perform hyperparameter tuning
tree_res <-
tree_wf %>%
tune_grid(
resamples = cell_folds,
grid = tree_grid
)
#| label: fig-2
#| fig-cap: Variation in model performance metrics with cost complexity across different number of tree depths.
tree_res %>%
collect_metrics() %>%
mutate(tree_depth = factor(tree_depth)) %>%
ggplot(aes(cost_complexity, mean, color = tree_depth)) +
geom_line(size = 1.5, alpha = 0.6) +
geom_point(size = 2) +
facet_wrap(~ .metric, scales = "free", nrow = 2) +
scale_x_log10(labels = scales::label_number()) +
scale_color_viridis_d(option = "plasma", begin = .9, end = 0) +
theme_bw() +
labs(title = "Relationship Between Cost Complexity and Model Effectiveness by Tree Depth")
top5_best_result <- tree_res %>%
show_best(metric = "accuracy")
format_cost_complexity <- function(x) {
sprintf("%.10f", x)
}
top5_best_result$cost_complexity <- lapply(top5_best_result$cost_complexity, format_cost_complexity)
kable(top5_best_result, format = "html",
caption = "Top 5 Best Hyperparameter Combinations by Mean Accuracy") %>%
kable_styling()
best_tree <- tree_res %>%
select_best(metric = "accuracy")
best_tree$cost_complexity <- lapply(best_tree$cost_complexity, format_cost_complexity)
kable(best_tree, format = "html",
caption = "Optimal Hyperparameter Combination") %>%
kable_styling()
final_wf <-
tree_wf %>%
finalize_workflow(best_tree)
final_fit <- final_wf %>%
fit(data = financebirds_tr)
final_fit
#| label: fig-3
#| fig-cap: Best Decision Tree Model Trained on Finance and Birdsongs Data
final_fit %>%
extract_fit_engine() %>%
rpart.plot(type=3, extra=1)
financebirds_ts_bestpred <- financebirds_ts %>%
mutate(ptype = predict(final_fit, financebirds_ts, type = "class")) %>%
mutate(ptype = pull(ptype))
# Calculate accuracy for confusion matrix
accuracy_table_bestpred <- financebirds_ts_bestpred %>%
count(type, ptype) %>%
group_by(type) %>%
mutate(Accuracy = n[type==ptype]/sum(n)) %>%
pivot_wider(names_from = "ptype",
values_from = n) %>%
select(type, birdsongs, finance, Accuracy)
# Calculate overall accuracy
accuracy_bestpred <- accuracy(financebirds_ts_bestpred, type, ptype)
kable(accuracy_table_bestpred, format = "html",
caption = "Confusion Matrix (Best Tree Model After Tuning)") %>%
kable_styling()
kable(accuracy_bestpred, format = "html",
caption = "Overall Accuracy (Best Tree Model After Tuning)") %>%
kable_styling()
set.seed(121)
bt_spec <- boost_tree() %>%
set_mode("classification") %>%
set_engine("xgboost")
fb_fit_bt <- bt_spec %>%
fit(type~., data = financebirds_tr)
fb_ts_bt_pred <- financebirds_ts %>%
mutate(ptype = predict(fb_fit_bt,
financebirds_ts)$.pred_class)
fb_ts_bt_pred_acc <- accuracy(fb_ts_bt_pred, type, ptype)
kable(fb_ts_bt_pred_acc, format = "html",
caption = "Overall Accuracy (Boosted Tree Model)") %>%
kable_styling()
fb_ts_bt_pred_table <- fb_ts_bt_pred %>%
count(type, ptype) %>%
group_by(type) %>%
mutate(Accuracy = n[type==ptype]/sum(n)) %>%
pivot_wider(names_from = "ptype",
values_from = n, values_fill = 0) %>%
select(type, birdsongs, finance, Accuracy)
kable(fb_ts_bt_pred_table, format = "html",
caption = "Confusion Matrix (Boosted Tree Model)") %>%
kable_styling()
#| label: fig-4
#| fig-cap: Boosted Tree Model Trained on Finance and Birdsongs Data
xgb.plot.tree(model = fb_fit_bt$fit, trees = 0, render = TRUE,
width = 10, height = 10)
set.seed(121)
rf_spec <- rand_forest(mtry=2, trees=1000) %>%
set_mode("classification") %>%
set_engine("randomForest")
fb_fit_rf <- rf_spec %>%
fit(type ~ ., data = financebirds_tr)
fb_fit_rf
fb_ts_rf_pred <- financebirds_ts %>%
mutate(ptype = predict(fb_fit_rf, financebirds_ts)$.pred_class)
fb_ts_rf_pred_acc <- accuracy(fb_ts_rf_pred, type, ptype)
kable(fb_ts_rf_pred_acc, format = "html",
caption = "Overall Accuracy (Random Forest Model)") %>%
kable_styling()
fb_ts_rf_pred_table <- fb_ts_rf_pred %>%
count(type, ptype) %>%
group_by(type) %>%
mutate(Accuracy = n[type==ptype]/sum(n)) %>%
pivot_wider(names_from = "ptype",
values_from = n, values_fill = 0) %>%
select(type, birdsongs, finance, Accuracy)
kable(fb_ts_rf_pred_table, format = "html",
caption = "Confusion Matrix (Random Forest Model)") %>%
kable_styling()
#| label: fig-5
#| fig-cap: Variable Importance Plot showing 'MeanDecreaseGini' on the X-axis. Higher values on the X-axis indicate greater importance of the corresponding variables in predicting the target outcome.
varImpPlot(fb_fit_rf$fit,
main = "Variable Importance Plot (Random Forest Model)",
col = "darkblue", pch = 19, lwd = 2, lty = 2)
# LDA Model
financebirds_tr$type <- factor(financebirds_tr$type)
lda_spec <- discrim_linear() %>%
set_mode("classification") %>%
set_engine("MASS", prior = c(0.5, 0.5))
lda_fit <- lda_spec %>%
fit(type ~ ., data = financebirds_tr)
# Logistic Model
log_reg <- logistic_reg() %>%
set_engine("glm") %>%
set_mode("classification")
log_fit <- log_reg %>%
fit(type ~ ., data = financebirds_tr)
# ROC curve for LDA model
lda_predicted_probs <- predict(lda_fit, financebirds_ts, type = "prob")
lda_prob_birdsongs <- lda_predicted_probs$.pred_birdsongs
lda_roc <- roc(financebirds_ts$type == "birdsongs", lda_prob_birdsongs)
# Calculate AUC for LDA model
lda_auc <- round(auc(lda_roc), 3)
# ROC curve for Logistic model
log_predicted_probs <- predict(log_fit, financebirds_ts, type = "prob")
log_prob_birdsongs <- log_predicted_probs$.pred_birdsongs
log_roc <- roc(financebirds_ts$type == "birdsongs", log_prob_birdsongs)
# Calculate AUC for Logistic model
log_auc <- round(auc(log_roc), 3)
# ROC curve for best tree model
besttree_predicted_probs <- predict(final_fit, financebirds_ts, type = "prob")
besttree_prob_birdsongs <- besttree_predicted_probs$.pred_birdsongs
besttree_roc <- roc(financebirds_ts$type == "birdsongs", besttree_prob_birdsongs)
# Calculate AUC for logistic model
besttree_auc <- round(auc(besttree_roc), 3)
# ROC curve for boosted tree model
bt_predicted_probs <- predict(fb_fit_bt, financebirds_ts, type = "prob")
bt_prob_birdsongs <- bt_predicted_probs$.pred_birdsongs
bt_roc <- roc(financebirds_ts$type == "birdsongs", bt_prob_birdsongs)
# Calculate AUC for logistic model
bt_auc <- round(auc(bt_roc), 3)
# ROC curve for random forest tree model
rf_predicted_probs <- predict(fb_fit_rf, financebirds_ts, type = "prob")
rf_prob_birdsongs <- rf_predicted_probs$.pred_birdsongs
rf_roc <- roc(financebirds_ts$type == "birdsongs", rf_prob_birdsongs)
# Calculate AUC for logistic model
rf_auc <- round(auc(rf_roc), 3)
#| label: fig-6
#| fig-cap: ROC Curve Comparison of Different Machine Learning Models. The ROC curves depict the performance of various models in classifying `birdsongs` (i.e. the positive class). Each curve represents a different model - Tuned Tree (blue), Boosted Tree (red), Random Forest (dark green), Linear Discriminant Analysis (LDA) (orange), and Logistic Regression (maroon). The area under the ROC curve (AUC) values for each model are provided in the legend.
# Plot ROC curve for the first model (Tuned Tree)
plot(besttree_roc, main = "ROC Curve Comparison",
col = "blue", lwd = 2, lty = 1)
# Add ROC curve for the second model (Boosted Tree)
lines(bt_roc, col = "red", lwd = 2, lty = 1)
# Add ROC curve for the third model (Random Forest)
lines(rf_roc, col = "darkgreen", lwd = 2, lty = 1)
# Add ROC curve for the fourth model (LDA)
lines(lda_roc, col = "orange", lwd = 2, lty = 1)
# Add ROC curve for the fifth model (Logistic)
lines(log_roc, col = "maroon", lwd = 2, lty = 1)
# Add legend for all models
legend("bottomright", legend = c(paste("Best Tree AUC =", besttree_auc),
paste("Boosted Tree AUC =", bt_auc),
paste("Random Forest AUC =", rf_auc),
paste("LDA AUC =", lda_auc),
paste("Log AUC =", log_auc)),
col = c("blue", "red", "darkgreen", "orange", "maroon"), lty = 1, lwd = 2, bty = "n",
inset = c(0, 0))
library(vip)
install.packages("vip")
library(vip)
vip(fb_fit_bt)
varImpPlot(fb_fit_bt$fit)
bt_engine <- extract_fit_engine(fb_fit_bt)
var_importance <- vip::vip(bt_engine)
var_importance
var_importance
extract_fit_engine(fb_fit_bt)
xgb.importance(model = fb_fit_bt$fit)
bt_var_importance <- xgb.importance(model = fb_fit_bt$fit)
kable(bt_var_importance, format = "html",
caption = "Variable Importance (Boosted Tree)") %>%
kable_styling()
